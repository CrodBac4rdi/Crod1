#!/usr/bin/env node
/**
 * CROD Testing Expert MCP Server
 * JavaScript-based fÃ¼r NixOS KompatibilitÃ¤t
 */

import { Server } from '@modelcontextprotocol/sdk/server/index.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import {
    CallToolRequestSchema,
    ListToolsRequestSchema,
} from '@modelcontextprotocol/sdk/types.js';

class TestingExpertMCP {
    constructor() {
        this.server = new Server({
            name: 'testing-expert',
            version: '1.0.0'
        }, {
            capabilities: {
                tools: {}
            }
        });
        
        this.setupHandlers();
    }

    setupHandlers() {
        this.server.setRequestHandler(ListToolsRequestSchema, async () => {
            return {
                tools: [
                    {
                        name: 'analyze_test_coverage',
                        description: 'Analyze test coverage and suggest improvements',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                test_code: {
                                    type: 'string',
                                    description: 'Test code to analyze'
                                },
                                source_code: {
                                    type: 'string',
                                    description: 'Source code being tested'
                                },
                                framework: {
                                    type: 'string',
                                    description: 'Testing framework: jest, pytest, mocha, junit'
                                }
                            },
                            required: ['test_code']
                        }
                    },
                    {
                        name: 'generate_test_cases',
                        description: 'Generate test cases for given code',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                code: {
                                    type: 'string',
                                    description: 'Code to generate tests for'
                                },
                                test_type: {
                                    type: 'string',
                                    description: 'Test type: unit, integration, e2e'
                                },
                                framework: {
                                    type: 'string',
                                    description: 'Testing framework preference'
                                }
                            },
                            required: ['code']
                        }
                    },
                    {
                        name: 'testing_best_practices',
                        description: 'Get testing best practices and strategies',
                        inputSchema: {
                            type: 'object',
                            properties: {
                                test_type: {
                                    type: 'string',
                                    description: 'Test type: unit, integration, e2e, performance'
                                },
                                language: {
                                    type: 'string',
                                    description: 'Programming language'
                                }
                            }
                        }
                    }
                ]
            };
        });

        this.server.setRequestHandler(CallToolRequestSchema, async (request) => {
            const { name, arguments: args } = request.params;

            switch (name) {
                case 'analyze_test_coverage':
                    return await this.analyzeTestCoverage(args.test_code, args.source_code, args.framework);
                case 'generate_test_cases':
                    return await this.generateTestCases(args.code, args.test_type, args.framework);
                case 'testing_best_practices':
                    return await this.getTestingBestPractices(args.test_type, args.language);
                default:
                    throw new Error(`Unknown tool: ${name}`);
            }
        });
    }

    async analyzeTestCoverage(testCode, sourceCode = '', framework = 'jest') {
        const analysis = {
            score: 100,
            coverage: [],
            missing: [],
            quality: [],
            suggestions: []
        };

        const testLines = testCode.split('\n');
        const sourceLines = sourceCode.split('\n');
        
        // Test structure analysis
        let testCount = 0;
        let assertionCount = 0;
        let mockCount = 0;
        
        for (let i = 0; i < testLines.length; i++) {
            const line = testLines[i].trim();
            
            // Count tests
            if (line.includes('it(') || line.includes('test(') || line.includes('def test_')) {
                testCount++;
            }
            
            // Count assertions
            if (line.includes('expect(') || line.includes('assert') || line.includes('should')) {
                assertionCount++;
            }
            
            // Count mocks
            if (line.includes('mock') || line.includes('stub') || line.includes('spy')) {
                mockCount++;
            }
        }
        
        // Analyze coverage
        if (testCount === 0) {
            analysis.missing.push('No tests found');
            analysis.score -= 50;
        } else if (testCount < 5) {
            analysis.coverage.push(`Only ${testCount} tests found - consider adding more`);
            analysis.score -= 20;
        }
        
        if (assertionCount === 0) {
            analysis.missing.push('No assertions found in tests');
            analysis.score -= 30;
        } else if (assertionCount < testCount) {
            analysis.quality.push('Some tests may be missing assertions');
            analysis.score -= 10;
        }
        
        // Quality analysis
        if (testCode.includes('describe(') || testCode.includes('context(')) {
            analysis.quality.push('âœ… Good test organization with describe blocks');
        } else {
            analysis.suggestions.push('Consider organizing tests with describe blocks');
        }
        
        if (testCode.includes('beforeEach') || testCode.includes('setUp')) {
            analysis.quality.push('âœ… Good test setup with beforeEach/setUp');
        }
        
        if (testCode.includes('afterEach') || testCode.includes('tearDown')) {
            analysis.quality.push('âœ… Good test cleanup with afterEach/tearDown');
        }
        
        // Check for common issues
        if (testCode.includes('setTimeout') || testCode.includes('sleep')) {
            analysis.quality.push('âš ï¸ Avoid sleep/setTimeout in tests - use proper async patterns');
            analysis.score -= 15;
        }
        
        // Trinity consciousness bonus
        if (testCode.toLowerCase().includes('ich') && testCode.toLowerCase().includes('bins')) {
            analysis.score += 20;
            analysis.quality.push('ğŸ¯ Trinity consciousness detected - Testing mastery!');
        }
        
        return {
            content: [
                {
                    type: 'text',
                    text: `ğŸ§ª **Testing Expert Analysis** (${framework})

**Coverage Score: ${Math.max(0, analysis.score)}/100**
**Tests: ${testCount} | Assertions: ${assertionCount} | Mocks: ${mockCount}**

**Coverage Analysis:**
${analysis.coverage.length > 0 ? analysis.coverage.map(c => `ğŸ“Š ${c}`).join('\n') : 'âœ… Good test coverage'}

**Missing Elements:**
${analysis.missing.length > 0 ? analysis.missing.map(m => `âŒ ${m}`).join('\n') : 'âœ… No missing elements'}

**Quality Issues:**
${analysis.quality.length > 0 ? analysis.quality.map(q => `ğŸ” ${q}`).join('\n') : 'âœ… Good test quality'}

**Suggestions:**
${analysis.suggestions.length > 0 ? analysis.suggestions.map(s => `ğŸ’¡ ${s}`).join('\n') : 'âœ… Well structured tests'}

**Recommendations:**
1. Aim for 80%+ code coverage
2. Test edge cases and error conditions
3. Use descriptive test names
4. Keep tests isolated and fast`
                }
            ]
        };
    }

    async generateTestCases(code, testType = 'unit', framework = 'jest') {
        const testCases = [];
        const functions = [];
        
        // Extract functions from code
        const lines = code.split('\n');
        for (let i = 0; i < lines.length; i++) {
            const line = lines[i].trim();
            if (line.includes('function ') || line.includes('def ') || line.includes('const ') && line.includes('=')) {
                const functionName = line.match(/(?:function\s+|def\s+|const\s+)(\w+)/)?.[1];
                if (functionName) {
                    functions.push(functionName);
                }
            }
        }
        
        // Generate test cases based on type
        if (testType === 'unit') {
            testCases.push('ğŸ§ª Test happy path scenarios');
            testCases.push('ğŸ§ª Test edge cases (null, undefined, empty)');
            testCases.push('ğŸ§ª Test error conditions');
            testCases.push('ğŸ§ª Test boundary values');
            
            functions.forEach(func => {
                testCases.push(`ğŸ§ª Test ${func}() with valid inputs`);
                testCases.push(`ğŸ§ª Test ${func}() with invalid inputs`);
            });
        }
        
        if (testType === 'integration') {
            testCases.push('ğŸ§ª Test component interactions');
            testCases.push('ğŸ§ª Test data flow between modules');
            testCases.push('ğŸ§ª Test API integrations');
            testCases.push('ğŸ§ª Test database operations');
        }
        
        if (testType === 'e2e') {
            testCases.push('ğŸ§ª Test user workflows');
            testCases.push('ğŸ§ª Test UI interactions');
            testCases.push('ğŸ§ª Test error handling');
            testCases.push('ğŸ§ª Test performance scenarios');
        }
        
        // Framework-specific examples
        let exampleCode = '';
        if (framework === 'jest') {
            exampleCode = `
**Jest Example:**
\`\`\`javascript
describe('${functions[0] || 'YourFunction'}', () => {
  it('should handle valid input', () => {
    expect(${functions[0] || 'yourFunction'}('test')).toBe('expected');
  });
  
  it('should throw on invalid input', () => {
    expect(() => ${functions[0] || 'yourFunction'}(null)).toThrow();
  });
});
\`\`\``;
        } else if (framework === 'pytest') {
            exampleCode = `
**Pytest Example:**
\`\`\`python
def test_${functions[0] || 'your_function'}_valid_input():
    result = ${functions[0] || 'your_function'}('test')
    assert result == 'expected'
    
def test_${functions[0] || 'your_function'}_invalid_input():
    with pytest.raises(ValueError):
        ${functions[0] || 'your_function'}(None)
\`\`\``;
        }
        
        return {
            content: [
                {
                    type: 'text',
                    text: `ğŸ§ª **Generated Test Cases** (${testType})

**Test Cases to Implement:**
${testCases.join('\n')}

**Functions Found:**
${functions.length > 0 ? functions.map(f => `ğŸ”§ ${f}()`).join('\n') : 'No functions detected'}

${exampleCode}

**Testing Strategy:**
1. Start with happy path tests
2. Add edge case coverage
3. Test error conditions
4. Verify all code paths
5. Add performance tests if needed

**CROD Testing Philosophy:**
ğŸ¯ Trinity consciousness = perfect test coverage
ğŸ”¥ Every function tested and verified
âš¡ Fast, reliable, maintainable tests`
                }
            ]
        };
    }

    async getTestingBestPractices(testType = 'unit', language = 'javascript') {
        const practices = {
            unit: {
                javascript: [
                    'ğŸ§ª Use describe blocks for organization',
                    'ğŸ§ª Write clear test names',
                    'ğŸ§ª Use beforeEach for setup',
                    'ğŸ§ª Mock external dependencies',
                    'ğŸ§ª Test one thing at a time',
                    'ğŸ§ª Use proper assertions',
                    'ğŸ§ª Test edge cases',
                    'ğŸ§ª Keep tests isolated'
                ],
                python: [
                    'ğŸ§ª Use pytest fixtures',
                    'ğŸ§ª Write descriptive test names',
                    'ğŸ§ª Use parametrized tests',
                    'ğŸ§ª Mock external calls',
                    'ğŸ§ª Test exceptions properly',
                    'ğŸ§ª Use assert statements',
                    'ğŸ§ª Test boundary conditions',
                    'ğŸ§ª Keep tests fast'
                ]
            },
            integration: {
                javascript: [
                    'ğŸ§ª Test component interactions',
                    'ğŸ§ª Use test databases',
                    'ğŸ§ª Test API endpoints',
                    'ğŸ§ª Verify data flow',
                    'ğŸ§ª Test error handling',
                    'ğŸ§ª Use realistic data',
                    'ğŸ§ª Test configuration',
                    'ğŸ§ª Monitor test performance'
                ],
                python: [
                    'ğŸ§ª Test module interactions',
                    'ğŸ§ª Use test fixtures',
                    'ğŸ§ª Test database operations',
                    'ğŸ§ª Verify API responses',
                    'ğŸ§ª Test error scenarios',
                    'ğŸ§ª Use factory patterns',
                    'ğŸ§ª Test middleware',
                    'ğŸ§ª Cleanup after tests'
                ]
            },
            e2e: [
                'ğŸ§ª Test user workflows',
                'ğŸ§ª Use page object pattern',
                'ğŸ§ª Test critical paths',
                'ğŸ§ª Use stable selectors',
                'ğŸ§ª Test across browsers',
                'ğŸ§ª Handle async operations',
                'ğŸ§ª Test error states',
                'ğŸ§ª Use proper wait strategies'
            ],
            performance: [
                'ğŸ§ª Set performance budgets',
                'ğŸ§ª Test load scenarios',
                'ğŸ§ª Monitor response times',
                'ğŸ§ª Test memory usage',
                'ğŸ§ª Use realistic data volumes',
                'ğŸ§ª Test concurrency',
                'ğŸ§ª Profile slow operations',
                'ğŸ§ª Set up alerts'
            ]
        };
        
        const testPractices = practices[testType];
        let selectedPractices;
        
        if (testPractices && typeof testPractices === 'object' && !Array.isArray(testPractices)) {
            selectedPractices = testPractices[language] || testPractices.javascript || [];
        } else {
            selectedPractices = testPractices || practices.unit.javascript;
        }
        
        return {
            content: [
                {
                    type: 'text',
                    text: `ğŸ§ª **Testing Best Practices** (${testType} - ${language})

${selectedPractices.join('\n')}

**Daniel's Testing Philosophy:**
ğŸ¯ Trinity consciousness: "ich bins wieder" = perfect test coverage
ğŸ”¥ For NixOS: Use nix-shell for consistent test environments
âš¡ CROD pattern: Everything tested, nothing broken!
ğŸ³ Docker: Consistent testing across environments

**Testing Pyramid:**
1. Unit tests (70%) - Fast, isolated
2. Integration tests (20%) - Component interactions
3. E2E tests (10%) - User workflows`
                }
            ]
        };
    }

    async start() {
        const transport = new StdioServerTransport();
        console.error('ğŸ§ª CROD Testing Expert MCP Server starting...');
        console.error('ğŸ” Ready to analyze your tests!');
        
        await this.server.connect(transport);
    }
}

// Start the server
const server = new TestingExpertMCP();
server.start().catch(console.error);